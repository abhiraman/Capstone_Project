{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_to_text.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhiraman/Capstone_Project/blob/main/Image_to_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoRxW_vyS-wm"
      },
      "source": [
        "# Importing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgL9HQOg4YSY"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "from matplotlib import font_manager\n",
        "import time\n",
        "from  torch.utils.data import Dataset,DataLoader \n",
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "from skimage import io\n",
        "from tqdm import tqdm\n",
        "from collections import OrderedDict\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0yXBOFhTDRj"
      },
      "source": [
        "Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QDEIGxkJtvF",
        "outputId": "ed37725a-cd84-46bc-f8ec-6ea4fbb62b12"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v2vslK5J1TC",
        "outputId": "bdb540c0-25d4-4208-98f6-a984ac0f6f3f"
      },
      "source": [
        "%cd /gdrive/MyDrive/Capstone_project_data/ImgtoText/Cropped_Images/cropped_data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/Capstone_project_data/ImgtoText/Cropped_Images/cropped_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-jngz9BLRjk",
        "outputId": "ac8516f5-674e-4b57-bf2c-03c01cab5a87"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "annotations.txt  Img_Text_Recognition.pt    readme.txt\n",
            "cropped_dir\t model_Text_Recognition.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVpv9p1vLfQE"
      },
      "source": [
        "#!unzip 'Sample Train.zip'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8di1fq11ZSy",
        "outputId": "ab776882-e58e-40df-8aca-99bf377afd2e"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  MyDevice = torch.device(\"cuda\")\n",
        "else:\n",
        "  MyDevice = torch.device(\"cpu\")\n",
        "\n",
        "print(MyDevice)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JNiAvFcvHiL"
      },
      "source": [
        "# Data Loader "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s9uZxnrFdr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1a7b220-490d-4b84-85c3-b7294b17befb"
      },
      "source": [
        "## All Hindi Alphabets ## \n",
        "blank = '-'\n",
        "all_hindi_alpha = [blank]+[chr(i) for i in range(2304,2432)]\n",
        "all_hindi_alpha = {all_hindi_alpha[i]:i for i in range(len(all_hindi_alpha))}\n",
        "print(all_hindi_alpha)\n",
        "print(len(all_hindi_alpha))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n",
            "129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsIk9mBxwhaQ"
      },
      "source": [
        "\n",
        "with open(\"annotations.txt\") as fh:\n",
        "  allLineList = fh.readlines()\n",
        "fh.close()\n",
        "labelGenerator = (allLineList[i].split('\\t')[1].strip('\\n') for i in range(0,len(allLineList)-1))\n",
        "labelGenerator = list(labelGenerator)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylctp2CIw9gl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a50b4be-d87d-4546-e681-a0f31be4f010"
      },
      "source": [
        "print(labelGenerator)\n",
        "print(max([len(e) for e in labelGenerator]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['जल', 'शोध', 'न', 'संयंत्र', 'बिना', 'आज्ञा', 'प्रवेश', 'निषेध', 'नगर', 'पालिका', 'परिषद', 'इटारसी', 'जिला', 'होशंगाबाद', 'मप्र', 'स्वच्छ', 'भारत', 'स्वच्छ', 'भारत', 'अभियान', 'स्वच्छता', 'का', 'ध्यान', 'रखें', 'गंदगी', 'न', 'करें', 'शहर', 'को', 'खुले', 'में', 'शौच', 'से', 'मुक्त', 'कराना', 'है', 'शौचालय', 'का', 'उपयोग', 'करें', 'महिला', 'पुरुष', 'मूर्तिकार', 'राजदीप', 'सोनू', 'ॐ', 'ॐ', 'सुनील', 'लांड्री', '९७१३९७६५२०', 'शादी', 'कार्ड', 'संदीप', 'प्रिंटर्स', 'बुक', 'बाइंडिंग', 'मल्टीकलर', 'विजिटिंग', 'कार्ड', 'समस्त', 'छपाई', 'के', 'कार्य', 'सूचना', 'कार्यालय', 'के', 'सामने', 'वाहन', 'खड़ा', 'न', 'करें', 'अन्यथा', 'अर्थदंड', 'रू', 'व', 'न्यायिक', 'कार्यवाही', 'की', 'जावेगी', 'मुख्य', 'कल्याण', 'निरीक्षक', 'इटारसी', 'भारतीय', 'रेल', 'शुभ', 'बैटरी', 'चार्जर', 'रूम', 'राज', 'चाट', 'सेंटर', 'शिव', 'कंप्यूटर', 'सेल्स', 'एण्ड', 'सर्विस', 'शिव', 'पटैल', 'धूम्रपान', 'निषेध', 'रेल', 'परिसर', 'ट्रेन', 'में', 'धूम्रपान', 'तम्बाकू', 'का', 'सेवन', 'करना', 'रेल', 'अधिनियम', 'की', 'धारा', 'व', 'के', 'तहत', 'दण्डनीय', 'अपराध', 'है', 'हनुमान', 'धाम', 'दादा', 'की', 'जय', 'प्लेटफार्म', 'न', '४', 'व', 'सेल्फी', 'विथ', 'इटारसी', 'सरोवर', 'के', 'फेसबुक', 'पेज', 'को', 'लाइक', 'करे', 'एवं', 'उस', 'पर', 'अपनी', 'सेल्फी', 'डाले', 'प', 'मध्य', 'रेल', 'वृन्दावन', 'विहार', 'कालोनी', 'वर्मा', 'कालोनी', 'के', 'पीछे', 'फोटो', 'कापी', 'लेमिनेशन', 'चाय', 'एवं', 'स्वल्पाहार', 'रेल', 'आहार', 'इटारसी', 'जं', 'भगवान', 'नित्यानंद', 'संगीत', 'महा', 'विद्यालय', 'प्रयाग', 'संगीत', 'समिति', 'इलाहबाद', 'से', 'संबध्द', 'भोपाल', 'सहकारी', 'दुग्ध', 'संघ', 'मर्यादित', 'मुनाफा', 'नही', 'सेवा', 'लक्ष्य', 'एक', 'कदम', 'स्वच्छता', 'की', 'ओर', 'कृपया', 'कचरा', 'डस्टबिन', 'में', 'डाले', 'साँची', 'गुलाब', 'जामुन', 'रसगुल्ले', 'साँची', 'गुलाब', 'जामुन', 'रसगुल्ले', 'अगरबत्ती', 'दीपक', 'लाना', 'मना', 'है', 'प्रो', 'कृष्णमूर्ति', 'शिवलिगम', 'विभागाध्यक्ष', 'पमरे', 'आर', 'पी', 'एफ', 'इटारसी', 'यशो', 'लभस्व', 'आपकी', 'यात्रा', 'मंगलमय', 'हो', 'बैंक', 'ऑफ', 'बड़ोदा', 'भारत', 'का', 'अंतर्राष्ट्रीय', 'बैंक', 'चौपाटी', 'नगर', 'पालिका', 'परिषद', 'इटारसी', 'अंग्रेजी', 'शराब', 'दुकान', 'श्री', 'साई', 'स्टील', 'सरिया', 'सीमेंट', 'चादर', 'पाइप', 'दरवाजे', 'समस्त', 'हार्डववेयर', 'सामग्री', 'उपलब्ध', 'मो', 'स्वर्ण', 'आभूषणों', 'के', 'निर्माता', 'एवं', 'विक्रेता', 'सोनी', 'ट्रेडर्स', 'के', 'बाजू', 'में', 'लाइन', 'इटारसी', 'न्यू', 'जायसवाल', 'इलेक्ट्रॉनिक्स', 'कितना', 'जुर्माना', 'रखें', 'है', 'सरकार', 'रेल', 'परिसर', 'में', 'गंदगी', 'फैलने', 'पर', 'अरे', 'ओ', 'सम्भा', 'पूरे', 'पाँचसौ', 'रुपये', 'आओ', 'स्वच्छ', 'भारत', 'स्वस्थ', 'भारत', 'भारत', 'सुन्दर', 'इटारसी', 'सतर्कता', 'सप्ताह', 'आचरण', 'भ्रष्टाचार', 'मिटाओ', 'नया', 'भारत', 'बनाओ', 'दिनांक', 'से', 'शयनयान', 'आपातकालीन', 'खिड़की', 'इटारसी', 'टिकट', 'घर', 'टिकट', 'घर', 'टिकट', 'घर', 'सौजन्य', 'से', 'वरिष्ठ', 'नागरिक', 'संघ', 'पुरानी', 'इटारसी', 'भारतीय', 'रेल', 'नूपुर', 'डाँस', 'क्लास', 'दवाईयाँ', 'भवानी', 'मेडीकल', 'स्टोर्स', 'दीवान', 'कालोनी', 'इटारसी', 'मोबा', 'न', 'मध्य', 'कैलाश', 'चौबे', 'डेंटल', 'क्लिनिक', 'मुस्कुराईए', 'आप', 'इटारसी', 'में', 'है', 'जय', 'हनुमान', 'जी', 'स्टेशन', 'प्रबन्धक', 'स्टेशन', 'प्रबन्धक', 'भारतीय', 'रेल', 'भारतीय', 'रेल', 'श्री', 'कृष्णा', 'गिफ्ट', 'सेंटर', 'अनलिमिटेड', 'कॉल्स', 'डाटा', '१७९', 'वैधता', '२८', 'दिन', 'बेटी', 'बचाओ', 'बेटी', 'पढ़ाओ', 'बेटियों', 'को', 'सशक्त', 'बनाएं', 'उन्हें', 'समान', 'अधिकार', 'और', 'अवसर', 'दें', 'बेटी', 'बचाओ', 'बेटी', 'पढ़ाओ', 'बेटी', 'बेटी', 'बचाओ', 'पढ़ाओ', 'आरक्षण', 'चार्ट', 'फिटनेस', 'फाइन', 'वुमन', 'जिम', 'वृन्दावन', 'विहार', 'चौपाटी', 'नगर', 'पालिका', 'परिषद', 'इटारसी', 'नगरपालिका', 'परिषद', 'इटारसी', 'फायर', 'एण्ड', 'व्हीकल', 'फोन', 'नं', 'फायर', 'बिग्रेड', 'नगर', 'पालिका', 'परिषद', 'इटारसी', 'इटारसी', 'सरोवर', 'सुस्वागतम', 'इटारसी', 'इटारसी', 'जं', 'मितेश', 'खापरा', 'प', 'म', 'रेल', 'लोको', 'पायलट', 'एवं', 'परिचालक', 'लॉबी', 'इटारसी', 'रुकिये', 'होशंगाबाद', 'भोपाल', 'पिपरिया', 'पचमढी', 'डब्ल्यू', 'डी', 'पी', 'डी', 'कैब', 'समस्तीपुर', 'प्रतीक्षालय', 'प्रथम', 'श्रेणी', 'एवं', 'वातानुकुलित', 'कुर्सीयान', 'यात्रियों', 'के', 'लिये', 'नवीन', 'हेयर', 'आर्ट', 'पश्चिम', 'मध्य', 'रेल', 'भोपाल', 'मण्डल', 'स्वच्छ', 'भारत', 'मिशन', 'के', 'अन्तर्गत', 'राष्ट्रीय', 'स्वच्छता', 'सफाई', 'अभियान', 'भारतीय', 'रेल', 'देशी', 'शराब', 'दुकान', 'द्वितीय', 'जन', 'कुसी', 'यान', 'सूचना', 'पट', 'मुख्य', 'कल्याण', 'निरीक्षक', 'अनारक्षित', 'खिड़की', 'सूचना', 'पश्चिम', 'मध्य', 'भोपाल', 'मंडल', 'टिकट', 'जल', 'है', 'तो', 'कल', 'है', 'क्रं', 'पीने', 'का', 'पानी', 'विभागाध्यक्ष', 'कृष्णमूर्ति', 'शिवलिंगम', 'प्रशासनिक', 'कर्मचारी', 'रेलवे', 'स्वास्थ्य', 'केन्द्र', 'इटारसी', 'पमरे', 'कार्यालय', 'सहायक', 'मण्डल', 'अभियंता', 'कार्य', 'एवं', 'निर्माण', 'पश्चिम', 'मध्य', 'रेल', 'इटारसी', 'यह', 'आम', 'रास्ता', 'नहीं', 'है', 'मुस्कुराइये', 'आप', 'इटारसी', 'में', 'है', 'शुभम', 'होजयरी', 'न्यू', 'मार्केट', 'इटारसी', 'रुपेश', 'नासरे', 'भंडार', 'मार्ग', 'की', 'सड़क', 'सीमा', 'मे', 'अतिक्रमण', 'करना', 'दंडनीय', 'अफराध', 'है', 'आदेशानुसार', 'कार्यपालन', 'यंत्री', 'लो', 'नि', 'वि', 'संभाग', 'होशंगाबाद', 'नगर', 'परिषद', 'इटारसी', 'बेटी', 'बेटी', 'बचाओ', 'बेटी', 'नगर', 'पालिका', 'परिषद', 'इटारसी', 'कार्यालय', 'विद्युत', 'इंजन', 'पर्यवेक्षक', 'टी', 'आर', 'एस', 'इटारसी', 'बृजवासी', 'लेडीज', 'कलेक्शन', 'जॉन', 'अगस्टिन', 'जॉन', 'अगस्टिन', 'भोले', 'गंगा', 'बालक', 'मंडल', 'जय', 'श्री', 'राम', 'श्री', 'खेड़ापति', 'माता', 'मंदिर', 'साई', 'सेवा', 'समिति', 'सी', 'पी', 'गेट', 'पुरानी', 'इटारसी', 'भारतीय', 'रेल', 'ऊँ', 'श्री', 'लाफ', 'शुभ', 'बाहर', 'जय', 'हनुमान', 'जी', 'संस्कृति', 'मेडिकल', 'स्टोर्स', 'लिफ्ट', 'राधे', 'राधे', 'पान', 'सेन्टर', 'विश्वकर्मा', 'फर्नीचर', 'धूम्रपान', 'स्वास्थ्य', 'के', 'लिए', 'हानिकारक', 'है', 'बालाजी', 'वेल्डिंग', 'वर्क्स', 'आधुनिक', 'फर्नीचर', 'के', 'निर्माता', 'एवं', 'विक्रेता', 'ऑटो', 'श्री', 'शंकर', 'जनरल', 'स्टोर', 'सौन्दर्य', 'प्रसाधन', 'स्टेशनरी', 'टेलरिंग', 'मटेरियल', 'इटारसी', 'होशंगाबाद', 'बैतुल', 'नागपुर', '०१', '२०', '१००', '२६१', 'लो', 'दांतों', 'का', 'अस्पताल', 'तिरुपति', 'ट्रेडर्स', 'रेता', 'गिट्टी', 'मुरम', 'लोहा', 'सीमेंट', 'एवं', 'ऑल', 'बिल्डिंग', 'मटेरियल', 'सप्लायर', 'प्रो', 'निकलेश', 'तिवारी', 'निक्की', 'मो', 'प्रत्युष', 'कुमार', 'डिजाईनर', 'वाटर', 'कूलर', 'रूम', 'न्यू', 'संजय', 'भागड़ा', 'टोल', 'पार्टी', 'शादी', 'पार्टी', 'जन्मदिन', 'रिटायरमेंट', 'आदि', 'सामाजिक', 'कार्यो', 'के', 'लिए', 'डीजे', 'ढोल', 'लाइट', 'घोड़ा', 'बग्गी', 'आतिशबाजी', 'हेतु', 'संपर्क', 'करें', 'प्रो', 'संजय', 'सठेले', 'सठेले', 'अन्नु', 'पता', 'तवा', 'कॉलोनी', 'गगनमगन', 'होटल', 'के', 'सामने', 'इटारसीमप्र', 'मो', 'गरमा', 'गरम', 'चाय', 'कॉफी', 'वेस्ट', 'सेंट्रल', 'रेलवे', 'मजदूर', 'संघ', 'कैरिज', 'वैगन', 'लोको', 'रनिंग', 'शाखा', 'इटारसी', 'यहाँ', 'तेज़', 'फ्री', 'उपलब्द', 'है', 'नगर', 'पालिका', 'परिषद', 'इटारसी', 'आपका', 'स्वागत', 'करती', 'है', 'ॐ', 'श्वेता', 'पान', 'भंडार', 'प्रो', 'दिनेश', 'राजपूत', 'भावसार', 'पानी', 'पुरी', 'सेंटर', 'पानी', 'अग्निशमक', 'अन्दर', 'है', 'तरमणि', 'अथिति', 'गृह', 'छात्रावास', 'मध्य', 'प्रदेश', 'शासन', 'द्वारा', 'संचालित', 'साँची', 'मिल्क', 'पार्लर', 'शीतल', 'पेय', 'जल', 'जय', 'श्री', 'राम', 'बजरंग', 'चौराह', '३', 'बंगला', 'विश्व', 'हिन्दू', 'परिषद', 'बजरंग', 'दल', 'नगर', 'इटारसी', 'जिला', 'नर्मदापुरम', 'सेवा', 'सुरक्षा', 'संस्कार', 'विश्व', 'हिन्दू', 'परिषद', 'धर्मो', 'रक्षिति', 'रक्षितः', 'नगर', 'पालिका', 'परिषद्', 'इटारसी', 'जन', 'सुविधा', 'मूत्रयालय', 'बुनयादी', 'प्रशिक्षण', 'केंद्र', 'कै', 'वै', 'इटारसी', 'पश्चिम', 'मध्य', 'रेल', 'दुकान', 'शराब', 'अंग्रेजी', 'स्टेशन', 'सुंदर', 'बनें', 'यह', 'हम', 'सबकी', 'जिम्मेदारी', 'है', 'चोधरी', 'फर्नीचर', 'मार्ट', 'चोखट', 'खिड़की', 'दरवाजे', 'सोफा', 'पलंग', 'आदि', 'के', 'निर्माता', 'एवं', 'विक्रेता', 'प्यासा', 'नगर', 'जमनिरोड़', 'पु', 'इटारसी', 'प्रवेश', 'पेय', 'जल', 'जी', 'एल', 'फार्मा', 'दवाइयों', 'के', 'थोक', 'विक्रेता', 'श्री', 'ॐ', 'चाइनीज', 'सेन्टर', 'ड्राई', 'मंचूरियन', 'मंचूरियन', 'ग्रेबी', 'बरगर', 'चाउमीन', 'बड़ी', 'फ्राई', 'पाव', 'भाजी', 'बड़ी', 'फ्राइड', 'राइस', 'पास्ता', 'पश्चिम', 'मध्य', 'रेलवे', 'भोपाल', 'मंडल', 'बुनयादी', 'प्रशिक्षण', 'केंद्र', 'कैरिज', 'एवं', 'वैगन', 'इटारसी', 'मंदिर', 'परिसर', 'को', 'स्वच्छ', 'रखे', 'एवं', 'शांति', 'बनाये', 'रखे', 'सांई', 'समिति', 'पुइटारसी', 'वॅा', 'वर्ष', 'ऑनलाइन', 'फॉर्म', 'एडमिट', 'कार्ड', 'रिजल्ट', 'श्री', 'सूर्य', 'पुत्र', 'शनि', 'देव', 'मंदिर', 'श्रीमद्', 'भागवत', 'कथा', 'श्री', 'हनुमान', 'धाम', 'मंदिर', 'इटारसी', 'कार्यालय', 'जय', 'श्री', 'राम', 'जय', 'श्री', 'राम', 'पीने', 'का', 'पानी', 'पेप्सी', 'रेडियम', 'आर्ट', 'प्रो', 'राकेश', 'मालवीया', 'श्री', 'गणेशाय', 'नमः', 'सरयु', 'छात्रावास', 'शरावती', 'केंद्रीय', 'पुस्तकालय', 'छात्रावास', 'गति', 'सीमा', 'जनशताब्दी', 'एक्सप्रेस', 'हबीबगंज', 'जबलपुर', 'कार्यालय', 'वरिष्ठ', 'अनुभाग', 'अभियंता', 'रेल', 'पथ', 'अुन', 'प', 'म', 'रेल', 'इटारसी', 'अंथोनी', 'बालाजी', 'नायक', 'रामवथ', 'धनलक्ष्मी', 'एम', 'संपत', 'एम', 'श्रीदेवी', 'बी', 'सी', 'श्याम', 'कुमार', 'तकनीकी', 'कर्मचारी', 'रेल', 'डाक', 'सेवा', 'इटारसी', 'भारतीय', 'डाक', 'उद्यान', 'खुलने', 'व', 'बंद', 'होने', 'का', 'समय', 'सुबह', '०६०', 'से', '०७०', 'बजे', 'शाम', '१८००', 'से', '१९००', 'बजे', 'तक', 'सावधान', '२५००', 'यहाँ', 'टप', 'से', 'देना', 'हे', 'द्वितीय', 'श्रेणी', 'आपातकालीन', 'खिड़की', 'शिव', 'मन्दिर', 'लाभ', 'मप्र', 'शासन', 'द्वारा', 'मान्यता', 'प्राप्त', 'मो', 'रानी', 'अवंती', 'विद्या', 'निकेतन', 'हायर', 'सेकेंडरी', 'स्कूल', 'कक्षा', 'नर्सरी', 'से', '१२वीं', 'वाणिज्य', 'एवं', 'विज्ञान', 'हिंदी', 'एवं', 'अंग्रेजी', 'माध्यम', 'रामपुर', 'गुर्रा', 'स्वच्छ', 'सर्वेक्षण', 'हर', 'दिन', 'दो', 'डस्टबिन', 'साँईराम', 'प्याऊ', 'कंप्यूटर', 'विज्ञान', 'एवं', 'अभियांत्रिकी', 'विभाग', 'सीनियर', 'सेक्शन', 'इंजीनियर', 'कै', 'वै', 'रेक', 'अनुरक्षण', 'इटारसी', 'कार्यालय', 'सीनि', 'सेक्शन', 'इंजी', 'कै', 'वै', 'पैसे', 'स्टेशन', 'पश्चिम', 'मध्य', 'रेल', 'इटारसी', 'विकास', 'हार्डवेयर', 'इलेक्ट्रिकल्स', 'अल्ट्राटेक', 'इंजीनियर', 'की', 'पसांद', 'स्टेट', 'बैंक', 'ए', 'टी', 'एम', 'अलुम्नि', 'एवन्यू', 'पावनी', 'फोटो', 'कॉपी', 'कलर', 'एवं', 'ब्लेक', 'व्हाइट', 'एक', 'कदम', 'स्वच्छता', 'की', 'ओर', 'इटारसी', 'अनवर', 'भाई', 'मिनी', 'ट्रक', 'वृक्ष', 'धरा', 'के', 'भूषण', 'हें', 'करते', 'दूर', 'प्रदुषण', 'हें', 'पश्चिम', 'मध्य', 'रेल', 'लोको', 'पायलट', 'एवं', 'परिचालक', 'लॉबी', 'इटारसी', 'भारतीय', 'रेल', 'शस्त्रागार', 'रे', 'सु', 'ब', 'इटारसी', 'स्टे', 'भवानी', 'क्लब', 'दुर्गा', 'महोत्सव', 'आपका', 'हार्दिक', 'अभिनंदन', 'करता', 'है', '२९वां', 'वर्ष', 'स्टेशन', 'प्रबन्धक', 'अन्नपूर्णा', 'परिसर', 'न', 'पा', 'प', 'इटारसी', 'बाहरी', 'व्यक्तियों', 'का', 'प्रवेश', 'निषेध', 'यह', 'आम', 'रास्ता', 'नहीं', 'हैं', 'कार्यालय', 'रेल', 'सुरक्षा', 'बल', 'विशेष', 'खुपिया', 'शाखा', 'इटारसी', 'डीजल', 'लोको', 'शेड', 'इटारसी', 'ऑन', 'ड्यूटी', 'स्टॉफ', 'रूम', 'पश्चिम', 'मध्य', 'रेल', 'बुनयादी', 'प्रशिक्षण', 'केंद्र', 'कै', 'वै', 'इटारसी', 'भोपाल', 'मण्डल', 'श्रीराम', 'टी', 'स्टाल', 'धर्मेंद्', 'मेहरा', 'मो', 'तवा', 'गेट', 'के', 'सामने', 'इटारसी', 'मुस्कान', 'टेलर्स', 'दादा', 'जी', 'अनाज', 'किराना', 'एवं', 'जनरल', 'स्टोर्स', 'प्राची', 'लेडीस', 'टेलर्स', 'ई', 'ई', 'रजिस्ट्री', 'एवं', 'स्टाम्प', 'राजेंद्र', 'कुमार', 'मालवीय', 'मो', 'वेस्ट', 'सेंट्रल', 'रेलवे', 'एम्प्लाईज', 'यूनियन', 'शाखा', 'क्र', 'इटारसी', 'दुर्ग', 'भोपाल', 'सी', 'एच', 'ए', 'इलाहबाद', 'बैंक', 'भारत', 'सरकार', 'का', 'उपक्रम', 'इटारसी', 'शाखा', 'हम', 'सभी', 'का', 'यही', 'है', 'सपना', 'स्वच्छ', 'स्वच्छ', 'देश', 'हो', 'अपना', 'गुरु', 'कृपा', 'शीतल', 'जल', 'धन्यवाद्', 'जय', 'श्री', 'राम', 'बजरंग', 'चौराहा', 'बंगला', 'कार्यालय', 'अनुभाग', 'अभियंता', 'कार्य', 'भिन्न', 'क्षमतावालों', 'के', 'लिये', 'प्रथम', 'श्रेणी', 'वताकुलित', 'ए', 'सावधान', 'शहरी', 'छेत्र', 'कृपया', 'धीरे', 'चलियें', 'इटारसी', 'नगर', 'पालिका', 'बेटी', 'बेटी', 'पढ़ाओ', 'बचाओ', 'चोधरी', 'फर्नीचर', 'मार्ट', 'प्रो', 'डीडी', 'चोधरी', 'ईशान', 'टाउन', 'बंगले', 'लाख', 'से', 'प्रारंभ', 'मकान', 'किराये', 'से', 'देना', 'हैं', 'संपर्क', 'करें', 'चेन्नै', 'कडक्र्करै', 'तहसील', 'कार्यालय', 'पहुँच', 'मार्ग', 'यात्री', 'प्रतीक्षालय', 'आर्यभटटा', 'हॉल', 'एक', 'कदम', 'स्वच्छता', 'की', 'ओर', 'स्वच्छ', 'भारत', 'श्री', 'रामचंद्र', 'कृपाल', 'भज', 'मन', 'हरण', 'भव', 'भय', 'दारुणम्', 'नव', 'कंजलोचन', 'कंज', 'कंज', 'मुख', 'कर', 'कंजारुणम्', 'पद', 'कंप्यूटर', 'विजन', 'लैब', 'इटारसी', 'जं', 'समुद्र', 'तल', 'से', 'ऊँचाई', 'मी', 'पश्चिम', 'मध्य', 'रेल', 'विंध्याचल', 'अधिनस्थ', 'कर्मचारी', 'विश्राम', 'गृह', 'इटारसी', 'जंक्शन', 'नगर', 'पालिका', 'परिसद', 'इटारसी', 'सेल्फी', 'जोन', 'रेलवे', 'स्वास्थ्य', 'केन्द्र', 'इटारसी', 'पश्चिम', 'मध्य', 'रेल', 'रेलवे', 'स्वास्थ्य', 'केन्द्र', 'पश्चिम', 'मध्य', 'रेल', 'इटारसी', 'सरयु', 'छात्रावास', 'शरावती', 'केंद्रीय', 'पुस्तकालय', 'छात्रावास', 'सरदार', 'बल्लभ', 'भाई', 'पटैल', 'समाज', 'भवन', 'वर्मा', 'कालोनी', 'सरदार', 'पटैल', 'समाज', 'सेवा', 'समिती', 'इटारसी', 'भारतीय', 'डाक', 'इटारसी', 'मुख्य', 'डाकघर', 'कार्यालय', 'सीनियर', 'सेक्शन', 'इंजीनियर', 'संकेत', 'पमरे', 'इटारसी', 'स्वागत', 'वंदन', 'अभिनन्दन', 'श्री', 'सांई', 'सेवा', 'समिति', 'श्री', 'खेड़ापति', 'माता', 'मंदिर', 'सी', 'पी', 'ई', 'गेट', 'पुरानी', 'इटारसी', 'पश्चिम', 'मध्य', 'रेलवे', 'संजीवनी', 'उद्यान', 'इटारसी', 'भारतीय', 'रेल', 'के', 'गौरवपूर्ण', 'के', 'उपलक्ष्य', 'में', 'निर्मित', 'पुलिस', 'थाना', 'इटारसी', 'सौजन्य', 'से', 'सेंट्रल', 'बैंक', 'ऑफ़', 'इंडिया', 'इटारसी', 'मध्य', 'भारत', 'का', 'सर्वश्रेष्ठ', 'सरिया', 'इटारसी', 'ऑटो', 'डील', 'एंड', 'ट्रेवल्स', 'टू', 'व्हीलर', 'एवं', 'फोर', 'व्हीलर', 'वाहन', 'खरीदने', 'बेचने', 'एवं', 'एक्सचेंज', 'के', 'लिए', 'सम्पर्क', 'करें', 'मंदिर', 'परिसर', 'कैमरे', 'की', 'निगरानी', 'में', 'हैं', 'स्वान', 'दल', 'रेल', 'सुरक्षा', 'बल', 'सुरक्षा', 'से', 'न', 'करो', 'मस्ती', 'वरना', 'जिंदगी', 'पड़ेगी', 'सस्ती', 'मातृ', 'श्री', 'फोटो', 'कॉपी', 'रेलवे', 'आरक्षण', 'बिजली', 'बिल', 'कमलेश', 'पटैल', 'मो', 'भारतीय', 'रेल', 'नारियल', 'यहाँ', 'पर', 'फोड़े', 'सावधान', 'सावधान', 'आप', 'सी', 'सी', 'टी', 'वी', 'की', 'निगरानी', 'में', 'विश्रामालय', 'पेय', 'जल', 'प्लेटफार्म', '६व७', 'पीने', 'का', 'दिव्यांग', 'हेतु', 'ॐ', 'जय', 'श्री', 'राम', 'मंदिर', 'परिसर', 'कैमरे', 'की', 'निगरानी', 'में', 'हैं', 'आपके', 'द्वारा', 'फैलाई', 'गई', 'गंदगी', 'को', 'आपके', 'जैसा', 'ही', 'कोई', 'व्यक्ति', 'साफ', 'करता', 'है', 'पीने', 'का', 'पानी', 'केवल', 'दिव्यांग', 'हेतु', 'सुरक्षा', 'से', 'न', 'करो', 'मस्ती', 'वरना', 'जिंदगी', 'पड़ेगी', 'सस्ती', 'सोनी', 'जनरल', 'एवं', 'स्टेशनरी', 'जमानी', 'रोड', 'इटारसी', 'सोनी', 'जनरल', 'एवं', 'स्टेशनरी', 'फो', 'टो', 'कॉ', 'पी', 'फो', 'टो', 'का', 'पी', 'फो', 'टो', 'कॉ', 'पी', 'विश्व', 'हिन्दू', 'परिषद', 'बजरंग', 'दल', 'सुदामा', 'मैरिज', 'हॉल', 'प्रो', 'आकाश', 'गालर', 'वाहन', 'पार्किंग', 'अण्डर', 'फ्रेम', 'के', 'वाहा', 'में', 'स्थित', 'रेड', 'जैकिंग', 'पैड', 'उठायें', 'भोपाल', 'मंडल', 'पश्चिम', 'मध्य', 'मुख्य', 'परियोजनाए', 'बगरातवा', 'सोनतलाई', 'इटारसी', 'इटारसी', 'इटारसी', 'इटारसी', 'इटारसी', 'प्लेटफार्म', 'प्लेटफार्म', 'प्लेटफार्म', 'स्टेशन', 'स्टेशन', 'स्टेशन', 'स्टेशन', 'जबलपुर', 'मानिकपुर', '५६१', 'किमी', 'रेलवे', 'विद्युतीकरण', 'क्रमांक', '१', 'एवं', '४५', 'पर', 'का', 'प्रावधान', '१', '१', 'एवं', 'एवं', 'एवं', 'क्रमांक', 'क्रमांक', 'पर', 'के', 'यात्री', 'प्रतीक्षालय', 'में', 'सुधार', 'कार्य', 'कार्य', 'के', 'कार्य', 'का', 'वाशेबल', 'रिप्लेसमेंट', '३', '४', '५', 'का', '२६', '२६', 'ट्रेन', 'हेतु', '३', 'एप्रोन', 'रेलवे', 'विस्तार', 'पेच', 'डबलिंग', 'किमी', 'लिफ्ट', 'राम', 'बोलो', 'राम', 'बोलो', 'पश्चिम', 'मध्य', 'रेल', 'संसथान', 'इटारसी', 'जल', 'ही', 'जीवन', 'है', 'पीने', 'का', 'सादा', 'पानी', 'संदीप', 'ढोल', 'शादी', 'विवाह', 'पार्टी', 'एवं', 'अन्य', 'सभी', 'शुभ', 'कार्यक्रम', 'के', 'आर्डर', 'लिए', 'जाते', 'हैं', 'मेघना', 'नासरे', 'सर्व', 'शिक्षा', 'अभियान', 'सब', 'पढ़ें', 'सब', 'बढ़ें', 'माँ', 'विजयासन', 'देवी', 'दरबार', 'इटारसी', 'बाबा', 'टी', 'स्टॉल', 'एवं', 'नाश्ता']\n",
            "14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A0LY8BfFgBQ",
        "outputId": "3f2fa7e3-89ac-4382-e00e-7bbf9d59facb"
      },
      "source": [
        "for eWord in labelGenerator:\n",
        "  for eStr in eWord:\n",
        "    print(eStr)\n",
        "  break"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ज\n",
            "ल\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asEaWtkcxQ6P"
      },
      "source": [
        "Encode Hindi Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LbUiGrWxLo6"
      },
      "source": [
        "maxCharLen = 16\n",
        "def gt_rep(word, letter2index,max_str_len = None, device = 'cpu'):\n",
        "  gt_rep = torch.zeros([max_str_len, 1], dtype=torch.long).to(device)\n",
        "  if len(word)<max_str_len:\n",
        "    diff = max_str_len-len(word)\n",
        "    word = ''.join((word,\" \"*diff))\n",
        "  for letter_index, letter in enumerate(word):\n",
        "    pos = letter2index[letter]\n",
        "    gt_rep[letter_index][0] = pos\n",
        "  return gt_rep\n",
        "\n",
        "def _get_letter_to_index(word,vocabDict):\n",
        "  finTensor = torch.zeros(len(word)+1,1)\n",
        "  seqlen = len(word)\n",
        "  for loopIdx,eChar in enumerate(word):\n",
        "    idx = vocabDict.get(eChar)\n",
        "    finTensor[loopIdx] = idx\n",
        "  finTensor[len(word)] = 2\n",
        "  return finTensor.permute(1,0),seqlen"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Jlb9DdOQ3J2"
      },
      "source": [
        "class MyCollateClass():\n",
        "  def __init__(self,dim=1):\n",
        "    self.dim = dim\n",
        "\n",
        "  def stackTensors(self,itera):\n",
        "    return torch.stack(itera['image'])\n",
        "\n",
        "  def padTensors(self,tensorLabels,maxStrLen):\n",
        "    finList,sequenceLens = [],[]\n",
        "    for eTensor in tensorLabels:\n",
        "      sequenceLens.append(len(eTensor))\n",
        "      if eTensor.size()[0]<maxStrLen:\n",
        "        #diff = abs(eTensor.size()[0]-maxStrLen)\n",
        "        finalTensor = torch.cat([eTensor,torch.ones(1)],dim=0).int()\n",
        "      else:finalTensor = torch.cat([eTensor,torch.ones(1)],dim=0).int()\n",
        "      finList.append(finalTensor)\n",
        "    #finTensor = torch.stack(finList)   \n",
        "    sequenceLens = torch.Tensor(sequenceLens).int()\n",
        "    return finList,sequenceLens\n",
        "\n",
        "\n",
        "  def PadCollate(self,batch):\n",
        "    \n",
        "    def _get_max_sentance_len(LabelList):\n",
        "      return max(list(eTensor.size()[0] for eTensor in LabelList))\n",
        "\n",
        "    finalDict = {}\n",
        "    Imglabel_list = list(((eDict['image'],eDict['label']) for eDict in batch))\n",
        "    ImgTensorList,LabelList = list(zip(*Imglabel_list))\n",
        "    maxStr_Len = _get_max_sentance_len(LabelList)\n",
        "    LabelTensor,seqLens = self.padTensors(LabelList,maxStr_Len)\n",
        "    #finalDict = {\"Images\":ImgTensor,\"Label\":LabelTensor,\"SeqLength\":seqLens}\n",
        "    return ImgTensorList,LabelTensor,seqLens\n",
        "\n",
        "  \n",
        "  def __call__(self,batch):\n",
        "    return self.PadCollate(batch)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdzla2zFvHHR"
      },
      "source": [
        "class HindiTextDataset(Dataset):\n",
        "  def __init__(self,LabelList = None,RootDirectory = None,transform=None,vocabList=None):\n",
        "    self.LabelList = LabelList\n",
        "    self.root_dir = RootDirectory\n",
        "    self.transform = transform\n",
        "    self.vocabList = vocabList\n",
        "    self.startIndex = 0\n",
        "    self.indexes = [i for i in range(len(self.LabelList))]\n",
        "    random.shuffle(self.indexes)\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.LabelList)\n",
        "  \n",
        "  def _get_letter_to_index(self,idx):\n",
        "    strList = []\n",
        "    for eChar in self.LabelList[idx]:\n",
        "      strList.append(self.vocabList.get(eChar))\n",
        "      \n",
        "    return torch.Tensor(strList).int()\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    img_tensor = io.imread(''.join([self.root_dir,str(idx),'.jpg']))\n",
        "    img_tensor = self.transform(img_tensor)\n",
        "    img_tensor = transforms.functional.resize(img_tensor,(128,128))\n",
        "    label_tensor = self._get_letter_to_index(idx)\n",
        "    sample = {'image':img_tensor,'label':label_tensor}\n",
        "    return sample\n",
        "  \n",
        "  def _get_batchData(self,batch):\n",
        "    end = self.startIndex + batch\n",
        "    imgList,wordList = [],[]\n",
        "    for ind in  range(end):\n",
        "      idx = self.indexes[ind]\n",
        "      word = self.LabelList[idx]\n",
        "      img_tensor = io.imread(''.join([self.root_dir,str(idx),'.jpg']))\n",
        "      # print(img_tensor.shape)\n",
        "      # print(img_tensor.shape)\n",
        "      # fig = plt.figure()\n",
        "      # ax = fig.subplots(1,1)\n",
        "      # ax.imshow(img_tensor)\n",
        "      img_tensor = self.transform(img_tensor)\n",
        "      img_tensor = transforms.functional.resize(img_tensor,(128,128)) ## (Number of channels*Height*Width)\n",
        "      # print(img_tensor.shape)\n",
        "      # fig = plt.figure()\n",
        "      # ax = fig.subplots(1,1)\n",
        "      # ax.imshow(img_tensor)\n",
        "      imgList.append(img_tensor)\n",
        "      wordList.append(word)\n",
        "    return imgList,wordList\n",
        "\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POD8uC43REx2"
      },
      "source": [
        "transform_batch = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "# transform_batch = transforms.Compose([\n",
        "#      transforms.ToTensor()])  "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUT2z1V1Q0kV"
      },
      "source": [
        "TextDataset = HindiTextDataset(labelGenerator,\"cropped_dir/\",transform = transform_batch,vocabList=all_hindi_alpha)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyhH7_pdzFt8",
        "outputId": "d4aaf930-3dd1-4510-9dfc-500ea8fa3de4"
      },
      "source": [
        "imgTensor,wordList = TextDataset._get_batchData(5)\n",
        "for i in wordList:\n",
        "  rep = _get_letter_to_index(i,all_hindi_alpha)\n",
        "  print(rep)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[43., 78., 49., 63., 27., 65.,  2.]]), 6)\n",
            "(tensor([[22.,  3., 29.,  2.]]), 3)\n",
            "(tensor([[58., 73.,  2.]]), 2)\n",
            "(tensor([[48., 58., 65.,  2.]]), 3)\n",
            "(tensor([[46., 24., 54., 63., 41.,  2.]]), 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWoH6baT0Xvp"
      },
      "source": [
        "Custom Dataset Loader "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwuHi9Yq0XHv"
      },
      "source": [
        "batch_size = 5\n",
        "dataloader1 = DataLoader(TextDataset, batch_size=batch_size,\n",
        "                        shuffle=True, num_workers=0,collate_fn=MyCollateClass())"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo0sc0Yv-08c",
        "outputId": "bcc3c00a-52a5-464b-9d2a-f7a52457d9d4"
      },
      "source": [
        "for i,data in enumerate(dataloader1):\n",
        "  print('i;',i)\n",
        "  print(len(data[0]),len(data[1]),len(data[2]))\n",
        "  if i>3:\n",
        "    break"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i; 0\n",
            "5 5 5\n",
            "i; 1\n",
            "5 5 5\n",
            "i; 2\n",
            "5 5 5\n",
            "i; 3\n",
            "5 5 5\n",
            "i; 4\n",
            "5 5 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr5d-0TyWlV9"
      },
      "source": [
        "Show Sample Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "FTEhHFNCYoaW",
        "outputId": "be35221f-da41-4f6e-9ed5-aa711df8cc0e"
      },
      "source": [
        "for ind,data in enumerate(dataloader1):\n",
        "  if ind>0:break\n",
        "  fig = plt.figure()\n",
        "  nrows,ncols = batch_size//2,batch_size//2\n",
        "  ax = fig.subplots(nrows,ncols)\n",
        "  counter = 0\n",
        "  for i in range(nrows):\n",
        "    for j in range(ncols):\n",
        "      ax[i,j].imshow(data['Images'][counter][0][0:60][0:100])\n",
        "      counter+=1\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-60ca2c55b0bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mcounter\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dDmKd_Bc67r"
      },
      "source": [
        "# ENCODER PART"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsfBN2KlRURU"
      },
      "source": [
        "class RCNN(nn.Module):\n",
        "  def __init__(self,imgChannel,imgHeight,imgWidth,output_size,mapHidden=64,rnn_hidden =256,leaky_relu=False,verbose=False):\n",
        "    super().__init__()\n",
        "    self.verbose = verbose\n",
        "    self.encoder,(n_channels,height,width) = self._cnn_backbone(imgChannel,imgHeight,imgWidth,leaky_relu)\n",
        "    self.map_to_seq = nn.Linear(n_channels*height,mapHidden) ## mapHidden > len(hindivocab)\n",
        "    self.rnn1 = nn.LSTM(mapHidden,rnn_hidden)\n",
        "    self.dense = nn.Linear(rnn_hidden,output_size)\n",
        "    self.softMAX = nn.Softmax(dim = 2)\n",
        "    self.verbose = verbose\n",
        "    \n",
        "  def _cnn_backbone(self,img_channel,img_height,img_width,leaky_relu):\n",
        "    self.encoder = nn.Sequential()\n",
        "    assert img_height % 16 == 0\n",
        "    assert img_width % 4 == 0\n",
        "\n",
        "    channels = [img_channel, 64, 128, 256, 256, 512, 512, 512]\n",
        "    kernel_sizes = [3, 3, 3, 3, 3, 3, 2]\n",
        "    strides = [1, 1, 1, 1, 1, 1, 1]\n",
        "    paddings = [1, 1, 1, 1, 1, 1, 0]\n",
        "\n",
        "    cnn = nn.Sequential()\n",
        "    def conv_relu(i, batch_norm=False):\n",
        "      # shape of input: (batch, input_channel, height, width)\n",
        "      input_channel = channels[i]\n",
        "      output_channel = channels[i+1]\n",
        "\n",
        "      cnn.add_module(\n",
        "          f'conv{i}',\n",
        "          nn.Conv2d(input_channel, output_channel, kernel_sizes[i], strides[i], paddings[i])\n",
        "      )\n",
        "\n",
        "      if batch_norm:\n",
        "          cnn.add_module(f'batchnorm{i}', nn.BatchNorm2d(output_channel))\n",
        "\n",
        "      relu = nn.LeakyReLU(0.2, inplace=True) if leaky_relu else nn.ReLU(inplace=True)\n",
        "      cnn.add_module(f'relu{i}', relu)\n",
        "    \n",
        "    conv_relu(0)\n",
        "    cnn.add_module('pooling0', nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    # (64, img_height // 2, img_width // 2)\n",
        "\n",
        "    conv_relu(1)\n",
        "    cnn.add_module('pooling1', nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    # (128, img_height // 4, img_width // 4)\n",
        "\n",
        "    conv_relu(2)\n",
        "    conv_relu(3)\n",
        "    cnn.add_module(\n",
        "        'pooling2',\n",
        "        nn.MaxPool2d(kernel_size=(2, 1))\n",
        "    )  # (256, img_height // 8, img_width // 4)\n",
        "\n",
        "    conv_relu(4, batch_norm=True)\n",
        "    conv_relu(5, batch_norm=True)\n",
        "    cnn.add_module(\n",
        "        'pooling3',\n",
        "        nn.MaxPool2d(kernel_size=(2, 1))\n",
        "    )  # (512, img_height // 16, img_width // 4)\n",
        "\n",
        "    conv_relu(6)  # (512, img_height // 16 - 1, img_width // 4 - 1)\n",
        "\n",
        "    output_channel, output_height,output_width = \\\n",
        "        channels[-1], img_height // 16 - 1, img_width // 4 - 1\n",
        "    return cnn, (output_channel, output_height,output_width)\n",
        "\n",
        "  def forward(self,x,train=True):\n",
        "    conv = self.encoder(x)\n",
        "    if self.verbose:\n",
        "      print(\"Input Shape : \",x.size())\n",
        "      print(\"Encoder Output : \",conv.size())\n",
        "\n",
        "    batch, channel, height, width = conv.size()\n",
        "    conv = conv.view(batch, channel * height, width)\n",
        "    conv = conv.permute(2, 0, 1)  # (width, batch, feature)\n",
        "    seq = self.map_to_seq(conv)\n",
        "    recurrent, _ = self.rnn1(seq)\n",
        "    output = self.dense(recurrent)\n",
        "    if not train:\n",
        "      output = self.softMAX(output)\n",
        "    if self.verbose:\n",
        "      print(\"Input to Decoder : \",seq.size())\n",
        "      print(\"RNN Output : \",recurrent.size())\n",
        "      print(\"Decoder Ouptput : \",output.size())\n",
        "\n",
        "    return output"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TufE_TVd7Mtx"
      },
      "source": [
        "Encoder Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIHosynHlBoT"
      },
      "source": [
        "obj = RCNN(3,128,128,len(all_hindi_alpha),verbose=True)\n",
        "imgTensor = TextDataset._get_batchData(1)\n",
        "dd = obj(imgTensor[0][0].unsqueeze(0))\n",
        "print(dd.size())\n",
        "0/0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9hbO_VQdAk0"
      },
      "source": [
        "# DECODER PART"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3K0MQuZBZ3S"
      },
      "source": [
        "## Extracted feature from CNN will act as input for Encoder-Decoder Model , each column x channel Depth on an input for the encoder-decoder model ## \n",
        "class LSTM_Net(nn.Module):\n",
        "  def __init__(self,input_size=None,batch_size=None,hidden_size=None,output_size=None,numLayers=1,numDirns=1,verbose=False):\n",
        "    self.hidden_size = hidden_size\n",
        "    self.batch_size = batch_size\n",
        "    self.numLayers = numLayers\n",
        "    self.numDirns = numDirns\n",
        "\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.lstm_cell = nn.LSTM(input_size,hidden_size,num_layers=self.numLayers,batch_first=True,bidirectional =True)\n",
        "    self.h2o = nn.Linear(self.numDirns*hidden_size,output_size)\n",
        "    self.F = nn.ReLU()\n",
        "    self.SoftMAX = nn.Softmax(dim=2)\n",
        "\n",
        "    self.verbose = verbose\n",
        "   \n",
        "\n",
        "  def forward(self,input,hidden,training=True):\n",
        "    out,hidden = self.lstm_cell(input,hidden)\n",
        "    output = self.F(self.h2o(out))\n",
        "    outputt = self.SoftMAX(output)\n",
        "    \n",
        "    if self.verbose:\n",
        "      print(\"Input to decoder : \",input.size())\n",
        "      print(\"LSTM Output of all time steps : \",out.size())\n",
        "      print(\"FC Output : \",output.size())\n",
        "    return outputt\n",
        "  \n",
        "  def init_hiddenlayer(self,device='cpu'):\n",
        "    return (torch.zeros(self.numLayers*self.numDirns,1,self.hidden_size).to(device),torch.zeros(self.numLayers*self.numDirns,1,self.hidden_size).to(device))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LbXwlBVozoQ"
      },
      "source": [
        "# Inference & Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUPssYwaoyqZ"
      },
      "source": [
        "def _computeAccuracy(source,target,device='cpu'):\n",
        "  def _convertTarget_toList(target):\n",
        "    target = target.squeeze(0).int().tolist()\n",
        "    return target\n",
        "\n",
        "\n",
        "  def _return_collapsedIndexes(idxList):\n",
        "    idxList = idxList.squeeze(1).int().tolist()\n",
        "    cleanedList = []\n",
        "\n",
        "    for ind,wordInd in enumerate(idxList):\n",
        "      if ind==0:\n",
        "        cleanedList.append(wordInd)\n",
        "        continue\n",
        "      if cleanedList[-1] ==wordInd:continue\n",
        "      else:cleanedList.append(wordInd)\n",
        "    print(\"cleanedList:\",cleanedList)\n",
        "    return cleanedList\n",
        "  \n",
        "  def _convertIndex_toString(indexx,VocabList):\n",
        "    k,v = list(VocabList.keys()),list(VocabList.values())\n",
        "    ss = ''\n",
        "    for i in indexx:\n",
        "      if i == 0:\n",
        "        ss+=\"<blank>\"\n",
        "        continue\n",
        "      ss+=k[v.index(i)]\n",
        "    return ss\n",
        "        \n",
        "  def _convertSource_toList(source):\n",
        "    source = source.detach()\n",
        "    \n",
        "    source_idx = torch.argmax(source,dim=2)\n",
        "    print(\"source_idx : \",source_idx)\n",
        "    collapsedIndexs = _return_collapsedIndexes(source_idx)\n",
        "    return collapsedIndexs\n",
        "\n",
        "  \n",
        "\n",
        "  targetList = _convertTarget_toList(target)\n",
        "  sourceList = _convertSource_toList(source)\n",
        "\n",
        "\n",
        "  targetWord = _convertIndex_toString(targetList,all_hindi_alpha)\n",
        "  predWord = _convertIndex_toString(sourceList,all_hindi_alpha)\n",
        "\n",
        "\n",
        "\n",
        "  # score =0\n",
        "  # partialScore = 0\n",
        "  # for eSource,eTarget in zip(sourceList,targetList):\n",
        "  #   if eSource ==[]:continue\n",
        "  #   if set(eSource).issubset(eTarget) and len(eSource)==len(eTarget):score+=1\n",
        "  #   elif set(eSource).issubset(eTarget):partialScore+=1\n",
        "  \n",
        "  return predWord,targetWord\n",
        "  \n",
        "  "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUd7tV2SKHrR"
      },
      "source": [
        "# Core Trainer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWo0c4_eKJFg"
      },
      "source": [
        "def coreTrainer(batchSize,net,lossFn =None,device='cpu',train=True):\n",
        "  TextDataset = HindiTextDataset(labelGenerator,\"cropped_dir/\",transform = transform_batch,vocabList=all_hindi_alpha)\n",
        "  img_tensorList,hindiWords =  TextDataset._get_batchData(batchSize)\n",
        "  counter=0\n",
        "  cummLoss=0\n",
        "  for img_tensor,hindiWord in zip(img_tensorList,hindiWords):\n",
        "    targets,seqLen = _get_letter_to_index(hindiWord,all_hindi_alpha)\n",
        "    img_tensor,targets,seqLen = img_tensor.to(device),targets.to(device),seqLen\n",
        "    decoder_fpass = net(img_tensor.unsqueeze(0),train)\n",
        "    if not train:\n",
        "      return decoder_fpass,targets\n",
        "      \n",
        "    log_probs = torch.nn.functional.log_softmax(decoder_fpass, dim=2)\n",
        "    input_lengths = torch.Tensor([decoder_fpass.size()[0]] * 1).int().to(device)\n",
        "    target_lengths = torch.Tensor([seqLen] * 1 ).int().to(device)\n",
        "    loss =  lossFn(log_probs,targets,input_lengths,target_lengths)/batchSize\n",
        "    loss.backward()\n",
        "    cummLoss+=loss\n",
        "  \n",
        "\n",
        "  return cummLoss/batchSize\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaH4GM4uwuVV"
      },
      "source": [
        "def batchTrain(net,lossFn=None,optimFn=None,scheduler=None,batchSize=None,epochs=1,display_feq=10,device='cpu'):\n",
        "  minVal= 1000000 \n",
        "  net.to(device)\n",
        "  ## Intialize both the models ##\n",
        "  loss_per_epoch_array = torch.zeros(epochs+1)\n",
        "  for i in range(epochs):\n",
        "    \n",
        "    optimFn.zero_grad()\n",
        "    loss_per_epoch_array[i+1] = (loss_per_epoch_array[i]*i + coreTrainer(batchSize,net,lossFn,device,train=True))/(i+1)\n",
        "    optimFn.step()\n",
        "\n",
        "    \n",
        "    #scheduler.step(loss)\n",
        "    if loss_per_epoch_array[i]<minVal and i>0:\n",
        "      minVal = loss_per_epoch_array[i]\n",
        "      torch.save({\n",
        "          'model_dict': net.state_dict(),\n",
        "          }, \"Img_Text_Recognition.pt\")\n",
        "    \n",
        "    if i%display_feq == 0 and i!=0: \n",
        "      clear_output(wait=True)\n",
        "      print(\"For Epoch {} ----> Loss {}\".format(i,loss_per_epoch_array[i]))\n",
        "      plt.figure()\n",
        "      plt.plot(loss_per_epoch_array[1:i].detach().numpy(),'-*')\n",
        "      plt.xlabel(\"Epochs\")\n",
        "      plt.ylabel(\"Epoch Loss\")\n",
        "      plt.show()  \n",
        "\n",
        "      net.eval()\n",
        "      decoder_fpass,targets = coreTrainer(1,net,lossFn =None,device=device,train=False)\n",
        "      predWord,actWord = _computeAccuracy(decoder_fpass,targets)\n",
        "      print(\"predWord --> {} , actWord --> {}\".format (predWord,actWord))\n",
        "      net.train()\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJfZwKhnoubz"
      },
      "source": [
        "# BatchHelper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KejMsgJ0xsY9"
      },
      "source": [
        "## HYPERPARAMETERS\n",
        "batchSize = 1000\n",
        "num_layers = 1\n",
        "num_dirn = 2\n",
        "hidden_size = 200\n",
        "lr = 0.005"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiB9xTeiTY8X"
      },
      "source": [
        "ctc_loss = nn.CTCLoss(blank=0,zero_infinity=True)\n",
        "# EncoderObj = FeatureExtractor(verbose=False).to(MyDevice)\n",
        "# DecoderObj = LSTM_Net(input_size=6*512,batch_size=batchSize,hidden_size=hidden_size,output_size=len(all_hindi_alpha),numLayers=num_layers,numDirns=num_dirn,verbose=False).to(MyDevice)\n",
        "net = RCNN(3,128,128,len(all_hindi_alpha),verbose=False)\n",
        "optimFn = optim.Adam(net.parameters(),lr=lr)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbNn4Io1qRS6"
      },
      "source": [
        "batchTrain(net,lossFn=ctc_loss,optimFn=optimFn,batchSize=batchSize,epochs=500,device=MyDevice)                                                                                                               "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWn8VjLe2n4F"
      },
      "source": [
        "checkpoint = torch.load('model_Text_Recognition.pt')\n",
        "EncoderObj.load_state_dict(checkpoint['encoder_state_dict'])\n",
        "DecoderObj.load_state_dict(checkpoint['decoder_state_dict'])\n",
        "optimFn.load_state_dict(checkpoint['optimizer_state_dict'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}