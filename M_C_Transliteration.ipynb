{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "M/C_Transliteration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNORLcE8KGLSJ2SF1mZ3Q7l",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhiraman/Capstone_Project/blob/main/M_C_Transliteration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tvoTXVpJeVN"
      },
      "source": [
        "# Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFVwbpaYJdl1"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import string,re\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVu7OSzhDREV"
      },
      "source": [
        "# Load Data from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY-Im6k5DLQM",
        "outputId": "e2424863-5a48-49b7-e83d-f847a335d1ea"
      },
      "source": [
        "!git clone -l -s git://github.com/GokulNC/NLP-Exercises cloned-repo"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'cloned-repo' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5LVtrQNHyFP",
        "outputId": "94715a1a-07ec-439e-e308-23efcb199f71"
      },
      "source": [
        "%cd cloned-repo"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/Capstone_project_data/cloned-repo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa01lfLNIBbu",
        "outputId": "39c62849-2a2f-41e0-a2df-14ca39ff1815"
      },
      "source": [
        "%cd Transliteration-Indian-Languages/Original-NEWS2012-data/Training\n",
        "!ls"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/Capstone_project_data/cloned-repo/Transliteration-Indian-Languages/Original-NEWS2012-data/Training\n",
            "model.pt\t\t\t  NEWS2012-Training-EnKa-11955.xml\n",
            "NEWS2012-Training-EnBa-14623.xml  NEWS2012-Training-EnMa-9000.xml\n",
            "NEWS2012-Training-EnHe-11501.xml  NEWS2012-Training-EnTa-11957.xml\n",
            "NEWS2012-Training-EnHi-13937.xml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq7BP0iIZy_u",
        "outputId": "e50d84a6-91c4-4e81-9e1d-2ee106df37cf"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  MyDevice = 'cuda'\n",
        "else:MyDevice = 'cpu'\n",
        "print(MyDevice)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTyZiCO9xEZE"
      },
      "source": [
        "Getting all Hindi & English letters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq2ssxlxa4IZ",
        "outputId": "bf98d761-4da6-445c-eb44-afe86c5c4cb8"
      },
      "source": [
        "## Get all hindi consonants ##\n",
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "pad = \"PAD\"\n",
        "hindi_alphabets = [pad]+[chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabets_indexed = {hindi_alphabets[i]:i for i in range(len(hindi_alphabets))}\n",
        "print(hindi_alphabets_indexed)\n",
        "\n",
        "english_alphabets = string.ascii_uppercase\n",
        "english_alphabets_indexed = {}\n",
        "english_alphabets_indexed[pad]=0\n",
        "for ind,char in enumerate(english_alphabets,start=1):\n",
        "  english_alphabets_indexed[char] = ind\n",
        "print(len(english_alphabets_indexed))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'PAD': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n",
            "27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF41Hul2xMhk"
      },
      "source": [
        "Clean String Lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI3hfqWgerAR"
      },
      "source": [
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "def _cleanEnglishWord(line):\n",
        "  line = line.replace('-',' ').replace(',',' ').upper()\n",
        "  line = non_eng_letters_regex.sub('', line)\n",
        "  return line.split()\n",
        "\n",
        "def _cleanLanguageWord(line):\n",
        "  line = line.replace('-',' ').replace(',',' ')\n",
        "  cleanedStr = ''\n",
        "  for eChar in line:\n",
        "    if eChar in  hindi_alphabets or eChar in ' ':\n",
        "      cleanedStr+=eChar\n",
        "  return cleanedStr.split()\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRuvAaLK9JUQ"
      },
      "source": [
        "# Custom Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF2DbN8AIOgN"
      },
      "source": [
        "class TextLoader(Dataset):\n",
        "  def __init__(self,xmlFile=None):\n",
        "    super().__init__()\n",
        "    self.fileName = xmlFile\n",
        "    self.allEngWords,self.allHindiWords = [],[]\n",
        "    self._read_clean_data()\n",
        "    self.shuffleIndices = list(range(len(self.allEngWords)))\n",
        "    random.shuffle(self.shuffleIndices)\n",
        "    self.startIndex = 0\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.allEngWords)\n",
        "\n",
        "  def _read_clean_data(self):\n",
        "    tree = ET.parse(self.fileName)\n",
        "    root = tree.getroot()\n",
        "    for child in root:\n",
        "      engWord = _cleanEnglishWord(child[0].text)\n",
        "      hindWord = _cleanLanguageWord(child[1].text)\n",
        "      if len(engWord)!=len(hindWord):\n",
        "        print(\"Skipping --> {} --- {}\".format(child[0].text,child[1].text))\n",
        "      for eWord in engWord:\n",
        "        self.allEngWords.append(eWord)\n",
        "      for eWord in hindWord:\n",
        "        self.allHindiWords.append(eWord)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return {\"EnglishWord\":self.allEngWords[idx],\"HindiWord\":self.allHindiWords[idx]}\n",
        "  \n",
        "  def _get_batch_words(self,batchSize,array):\n",
        "    end= self.startIndex + batchSize\n",
        "    batch = []\n",
        "    return batch + [array[self.shuffleIndices[i]] for i in range(end)]\n",
        "  \n",
        "  def _return_batch_words(self,batchSize):\n",
        "    engWords = self._get_batch_words(batchSize,self.allEngWords)\n",
        "    hindiWords = self._get_batch_words(batchSize,self.allHindiWords)\n",
        "    return engWords,hindiWords\n",
        "\n",
        "dataSet = TextLoader(xmlFile='NEWS2012-Training-EnHi-13937.xml')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y3ai8-CJpEK",
        "outputId": "67c0565c-7f60-48a2-e553-04c02b7315bb"
      },
      "source": [
        "for ind,i in enumerate(dataSet):\n",
        "  if ind>5:break\n",
        "  print(i)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'EnglishWord': 'RAASAVIHAAREE', 'HindiWord': 'रासविहारी'}\n",
            "{'EnglishWord': 'DEOGAN', 'HindiWord': 'देवगन'}\n",
            "{'EnglishWord': 'ROAD', 'HindiWord': 'रोड'}\n",
            "{'EnglishWord': 'SHATRUMARDAN', 'HindiWord': 'शत्रुमर्दन'}\n",
            "{'EnglishWord': 'MAHIJUBA', 'HindiWord': 'महिजुबा'}\n",
            "{'EnglishWord': 'SABINE', 'HindiWord': 'सैबिन'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAMgSe9QPfjp"
      },
      "source": [
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[\"PAD\"]\n",
        "    rep[letter_index+1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[\"PAD\"]\n",
        "    return gt_rep"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiXYzmhp9lDy"
      },
      "source": [
        "Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC-8a_9M9qy6",
        "outputId": "6ddaba23-284f-423c-979c-ea7e1c6c5282"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zMNAcvQ92t-",
        "outputId": "a79764c9-eead-4a6c-cccf-24f88db17ec6"
      },
      "source": [
        "%cd /gdrive/MyDrive/Capstone_project_data\n",
        "!ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/Capstone_project_data\n",
            " cloned-repo  'Synthetic Train Set - Detection & Recognition'\n",
            " ImgtoText    'Synthetic Train Set - Detection & Recognition.zip'\n",
            " model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRGKOd1JCBfj"
      },
      "source": [
        "Enoder Decoder W/O Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImCxj2j59R-H"
      },
      "source": [
        "class Encoder_Decoder(nn.Module):\n",
        "  def __init__(self,inputSize,hiddenSize,outputSize,num_layers =1,num_dirns=1,verbose=True):\n",
        "    super().__init__()\n",
        "    self.hiddenSize = hiddenSize\n",
        "    self.outputSize = outputSize\n",
        "    self.num_layers = num_layers\n",
        "    self.num_dirns = num_dirns\n",
        "    self.encoder_GRU = nn.GRU(inputSize,hiddenSize)\n",
        "    self.decoder_GRU = nn.GRU(outputSize,hiddenSize)\n",
        "    self.h2o = nn.Linear(hiddenSize,outputSize)\n",
        "    self.F = nn.LogSoftmax(dim=2)\n",
        "    self.Fll = nn.Softmax(dim=2)\n",
        "    self.verbose = verbose\n",
        "  \n",
        "  def forward(self,inputs,maxCharLen,GT=None,trainFlag =True,device='cpu'):\n",
        "    all_hidden,last_hidden = self.encoder_GRU (inputs)\n",
        "\n",
        "    if self.verbose:\n",
        "      print(\"Encoder Input : \",inputs.size())\n",
        "      print(\"Encoder All Hidden Outputs : \",all_hidden.size())\n",
        "      print(\"Encoder Last Hidden Output : \",last_hidden.size())\n",
        "\n",
        "\n",
        "    decoder_state = last_hidden\n",
        "    decoderInput = torch.zeros(1,all_hidden.size()[1],self.outputSize).to(device) ##(1,batchSize,no.of English Alphabets)\n",
        "    if self.verbose:\n",
        "      print(\"Decoder Input : \",decoderInput.size())\n",
        "    \n",
        "\n",
        "    outputlist = []   \n",
        "    for i in range(maxCharLen):\n",
        "      out,decoder_state = self.decoder_GRU(decoderInput,decoder_state)\n",
        "      output = self.h2o(decoder_state)\n",
        "      output = self.F(output)\n",
        "\n",
        "      if trainFlag:\n",
        "        outputlist.append(output.view(1, -1))\n",
        "      else:\n",
        "        output_eval = self.Fll(self.h2o(out))\n",
        "        outputlist.append(output_eval.squeeze(0))\n",
        "      if self.verbose:\n",
        "        print(\"Decoder Ouput : \",output.size())\n",
        "        print(\"Squeezed Final Output : \",output.squeeze(0).size())\n",
        "        \n",
        "\n",
        "      maxIndexes = torch.argmax(output,dim=2,keepdim=True).type(torch.int64)\n",
        "      if GT!=None:\n",
        "        maxIndexes = GT[i].reshape(1, 1, 1)\n",
        "\n",
        "      one_hot = torch.FloatTensor(output.size()).to(device)\n",
        "      one_hot.zero_()\n",
        "      one_hot.scatter_(2,maxIndexes,1)\n",
        "      decoderInput = one_hot.detach()\n",
        "    return outputlist\n",
        "      \n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UpaT0WOH9Ey"
      },
      "source": [
        "def trainBatch(modelObj,batchSize,optFn,LossFn,enforceTrain=False,device='cpu'):\n",
        "  textLoaderObj = TextLoader(xmlFile='NEWS2012-Training-EnHi-13937.xml')\n",
        "  engList,hindiList = textLoaderObj._return_batch_words(batchSize)\n",
        "\n",
        "  total_loss = 0\n",
        "  batch_counter = 0\n",
        " \n",
        "  for eWord,hWord in zip(engList,hindiList):\n",
        "    inputs,targets = word_rep(hWord,hindi_alphabets_indexed,device=device),gt_rep(eWord,english_alphabets_indexed,device=device)\n",
        "    pred_ouputs = modelObj(inputs,len(targets),GT= targets if enforceTrain else None,device=device)\n",
        "    ## Loss & Gradient compute for evry time step ##\n",
        "    for index,ouputs in enumerate(pred_ouputs):\n",
        "      loss = LossFn(ouputs,targets[index])/batchSize ## Loss per word\n",
        "      loss.backward(retain_graph=True)\n",
        "      total_loss+=loss.item()        ## Total Loss per batch\n",
        "  \n",
        "\n",
        "  return total_loss/batchSize   ## Total Loss per Epoch\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxSd_pnaGt12"
      },
      "source": [
        "def training_helper(net,lr=0.5,batch_size=100,epochs=11,momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "  net.to(device)\n",
        "  lossFn = nn.NLLLoss(ignore_index = -1)\n",
        "  optFn = optim.Adam(modelObj.parameters(),lr=lr)\n",
        "  enforce_Till = epochs//3\n",
        "  sheduler = optim.lr_scheduler.StepLR(optFn,step_size=100,gamma=0.5)\n",
        "  \n",
        "\n",
        "\n",
        "  loss_per_epoch_array = torch.zeros(epochs+1)\n",
        "  minVal= 1000000\n",
        "  for i in range(epochs):\n",
        "    optFn.zero_grad()\n",
        "    loss_per_epoch_array[i+1] = (loss_per_epoch_array[i]*i + trainBatch(net, batch_size,optFn, lossFn, device = device, enforceTrain=True if i<enforce_Till else False ))/(i + 1)\n",
        "    optFn.step()\n",
        "    sheduler.step()\n",
        "    \n",
        "    if sheduler.get_lr()!=sheduler.get_last_lr():\n",
        "      print(sheduler.get_lr())\n",
        "\n",
        "    if loss_per_epoch_array[i]<minVal and i>0:\n",
        "      minVal = loss_per_epoch_array[i]\n",
        "      torch.save(net,'model.pt')\n",
        "\n",
        "    if i%display_freq == 0 and i!=0: ## Every 5 epochs refresh the loss plot ##\n",
        "      clear_output(wait=True)\n",
        "      print(\"For Epoch {} ----> Loss {}\".format(i,loss_per_epoch_array[i]))\n",
        "      plt.figure()\n",
        "      plt.plot(loss_per_epoch_array[1:i],'-*')\n",
        "      plt.xlabel(\"Epochs\")\n",
        "      plt.ylabel(\"Epoch Loss\")\n",
        "      plt.show()\n",
        "  return loss_per_epoch_array\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7cucnEpHev0"
      },
      "source": [
        "## HyperParameters ##\n",
        "hiddensize = 256\n",
        "lr = 0.005\n",
        "momentum = 0.9\n",
        "batch_size=64"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VJqSyWSGrRP"
      },
      "source": [
        "modelObj = Encoder_Decoder(len(hindi_alphabets_indexed),hiddensize,len(english_alphabets_indexed),verbose=False)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "ow2qfeaD5Tn4",
        "outputId": "91f42f02-23df-4825-c3fb-4e142f082f6b"
      },
      "source": [
        "training_helper(modelObj,lr=lr, momentum = momentum,batch_size=batch_size,epochs=1000,display_freq=10,device=MyDevice)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Epoch 990 ----> Loss 0.15560877323150635\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2.44140625e-06]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.3675, 0.3634,  ..., 0.1555, 0.1554, 0.1555])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuTb7hNX83hz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465af6d2-a00c-4b85-9598-851c0e862621"
      },
      "source": [
        "torch.load('model.pt',map_location=torch.device('cpu'))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoder_Decoder(\n",
              "  (encoder_GRU): GRU(129, 256)\n",
              "  (decoder_GRU): GRU(27, 256)\n",
              "  (h2o): Linear(in_features=256, out_features=27, bias=True)\n",
              "  (F): LogSoftmax(dim=2)\n",
              "  (Fll): Softmax(dim=2)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ2LNpTW7dGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f83060d-dac8-4b9c-b38a-73110b036fb6"
      },
      "source": [
        "def test(net,data,tar_len,device='cpu'):\n",
        "  key,val = list(english_alphabets_indexed.keys()),english_alphabets_indexed.values()\n",
        "  net.eval().to(device)\n",
        "  outputs = net(data,tar_len,trainFlag=False)\n",
        "  convertedList = [[] for i in range(outputs[0].size()[0])]\n",
        "  for eTensor in outputs:\n",
        "    indexes = torch.argmax(eTensor,dim=1).tolist()\n",
        "    strr = ''\n",
        "    for i,index in enumerate(indexes):\n",
        "      strr = key[index]\n",
        "      convertedList[i].append(strr)\n",
        "  return convertedList\n",
        "\n",
        "textLoaderObj = TextLoader(xmlFile='NEWS2012-Training-EnHi-13937.xml')\n",
        "engList,hindiList = textLoaderObj._return_batch_words(10)\n",
        "key = list(hindi_alphabets_indexed.keys())\n",
        "\n",
        "i=0\n",
        "for eWord,hWord in zip(engList,hindiList):\n",
        "  inputs,targets = word_rep(hWord,hindi_alphabets_indexed,device=MyDevice),gt_rep(eWord,english_alphabets_indexed,device=MyDevice)\n",
        "  pred = test(modelObj,inputs,len(targets))\n",
        "  tempList = []\n",
        "  for eTensor in inputs:\n",
        "    maxIndex = torch.argmax(eTensor,dim=1)\n",
        "    tempList.append(key[int(maxIndex.item())])\n",
        "\n",
        "  pred = [\"\".join(eChar) for eList in pred for eChar in eList  if eChar!='PAD' ]\n",
        "  tempList = [\"\".join(eChar) for eChar in tempList]\n",
        "  print(pred,tempList)\n",
        "  i+=1\n",
        "  if i>5:break\n",
        "\n",
        "  "
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['G', 'E', 'T', 'T'] ['ग', 'े', 'ट', 'PAD']\n",
            "['B', 'R', 'O', 'O', 'N'] ['ब', '्', 'र', 'ा', 'उ', 'न', 'PAD']\n",
            "['S', 'A', 'R', 'G', 'A', 'G', 'I'] ['स', 'र', 'ा', 'ज', 'े', 'व', 'ो', 'PAD']\n",
            "['S', 'E', 'M', 'I', 'L', 'O', 'L', 'L'] ['स', 'े', 'म', 'ी', 'न', 'ो', 'ल', 'PAD']\n",
            "['A', 'R', 'R', 'A', 'D'] ['ए', 'र', '्', 'ड', 'र', 'ा', 'PAD']\n",
            "['A', 'N', 'N', 'A', 'A', 'D', 'I', 'I'] ['आ', 'न', 'ं', 'द', 'म', 'य', 'ी', 'PAD']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-YS2j7if2QQ"
      },
      "source": [
        "batchSize = 1\n",
        "testSet = TextLoader(xmlFile='NEWS2012-Testing-EnHi-1000.xml')\n",
        "data = DataLoader(dataSet,batch_size=batchSize,shuffle=True,collate_fn=CustomWordLoader())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv8GTwaxl9Aj"
      },
      "source": [
        "aa = [1,2,3,5,6]\n",
        "b= 0\n",
        "if b<"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}